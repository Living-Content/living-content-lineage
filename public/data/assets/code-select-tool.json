{
  "claim_generator": "LivingContent/1.0.0",
  "claim_generator_info": [{ "name": "Living Content", "version": "1.0.0" }],
  "title": "Tool Selector",
  "format": "application/vnd.livingcontent.code+python",
  "instance_id": "urn:uuid:code-select-tool",

  "assertions": [
    {
      "label": "c2pa.actions",
      "data": {
        "actions": [{
          "action": "c2pa.created",
          "digitalSourceType": "http://cv.iptc.org/newscodes/digitalsourcetype/algorithmicMedia",
          "softwareAgent": { "name": "Living Content Pipeline", "version": "1.0.0" },
          "when": "2026-01-14T18:15:19Z"
        }]
      }
    },
    {
      "label": "lco.code",
      "data": {
        "function": "_llm_select",
        "module": "core.execution.selector",
        "computation": "select_tool",
        "hash": "sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
      }
    },
    {
      "label": "lco.execution",
      "data": {
        "execution_start_time": "1768414495.7448554",
        "execution_end_time": "1768414497.619668",
        "execution_duration_ms": 1874.81,
        "previous_function": "_consume_query",
        "next_function": "retrieve_history"
      }
    }
  ],

  "source_code": "@chain_link(\n    computation=\"select_tool\",\n    input_asset_type=\"model\",\n    output_asset_type=\"document\",\n)\nasync def _llm_select(self, user_query: str, candidates: list[dict]) -> dict:\n    \"\"\"Use LLM to select the best tool from candidates.\n\n    Returns:\n        Dict with tool_id (str | None) and metadata for lineage tracking.\n    \"\"\"\n    logger.info(f\"Candidates: {candidates}\")\n    llm_client = get_config(\"tools.tool_selector.llm.client\")\n    llm_prompt = get_prompt_content(\"tools.tool_selector.selection\")\n    task_config = get_llm_task_config(llm_client, \"tool_selection\")\n    model = task_config[\"model\"]\n    token_limit = task_config[\"token_limit\"]\n    retry_token_limit = task_config[\"retry_token_limit\"]\n    logger.info(f\"Using model: {model}, token_limit: {token_limit}\")\n\n    tools_desc = self._build_tools_desc(candidates)\n    prompt = llm_prompt.format(user_query=user_query, tools_desc=tools_desc)\n\n    logger.info(f\"Prompt:\\n{prompt}\")\n\n    async with track_llm_call(\"tool_selection\", model) as tracker:\n        try:\n            selected, metadata = await self._generate_llm_response(\n                prompt=prompt,\n                llm_client=llm_client,\n                model=model,\n                token_limit=token_limit,\n            )\n            tracker.record(metadata)\n            set_model_metadata(metadata)\n            tool_id = self._match_candidate(selected, candidates)\n            return {\n                \"tool_id\": tool_id,\n                \"model\": model,\n                \"candidates\": [c[\"tool_id\"] for c in candidates],\n                \"llm_response\": selected,\n                **metadata,\n            }\n\n        except TokenLimitExceededError:\n            logger.warning(\n                f\"Tool selection hit token limit ({token_limit}), \"\n                f\"retrying with {retry_token_limit}\"\n            )\n            selected, metadata = await self._generate_llm_response(\n                prompt=prompt,\n                llm_client=llm_client,\n                model=model,\n                token_limit=retry_token_limit,\n            )\n            metadata[\"retry\"] = True\n            metadata[\"original_token_limit\"] = token_limit\n            tracker.record(metadata)\n            set_model_metadata(metadata)\n            tool_id = self._match_candidate(selected, candidates)\n            return {\n                \"tool_id\": tool_id,\n                \"model\": model,\n                \"candidates\": [c[\"tool_id\"] for c in candidates],\n                \"llm_response\": selected,\n                **metadata,\n            }",

  "signature_info": {
    "alg": "ES256",
    "issuer": "did:key:zQ3shwc61yUNaJZBX2L9mZd3xhWjTEqD52dA3JxBnZnu78E3d",
    "time": "2026-01-14T18:15:19Z"
  }
}
